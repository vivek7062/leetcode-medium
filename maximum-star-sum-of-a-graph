// Question - https://leetcode.com/problems/maximum-star-sum-of-a-graph/
// Answer in cpp


class Solution {
public:
    int maxStarSum(vector<int>& vals, vector<vector<int>>& edges, int k) {
        int len = vals.size();
        int ans = INT_MIN;
        vector<vector<int>> add(len);
        for(int i=0;i<edges.size();i++){
            if(vals[edges[i][1]]>0) add[edges[i][0]].push_back(vals[edges[i][1]]);
            if(vals[edges[i][0]]>0) add[edges[i][1]].push_back(vals[edges[i][0]]);
        }
        for(int i=0;i<len;i++){
            sort(add[i].rbegin(),add[i].rend());
            int temp = vals[i];
            int tempLen = add[i].size();
            int size  = min(k,tempLen);
            for(int j=0;j<size;j++){
                temp+=add[i][j];
            }
            ans = max(ans,temp);
        }
        return ans;
    }
};
